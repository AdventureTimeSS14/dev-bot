import disnake
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from config import (
    AUTHOR,
    GLOBAL_SESSION,
    REPOSITORIES,
)

async def get_github_link(repo_code, number):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ GitHub issue –∏–ª–∏ PR –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Å—ã–ª–∫—É.
    """
    repo_name = REPOSITORIES.get(repo_code)
    if not repo_name:
        print(f"‚ö†Ô∏è –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –∫–æ–¥–æ–º {repo_code} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None

    base_api_url = f"https://api.github.com/repos/{AUTHOR}/{repo_name}"
    pr_url = f"{base_api_url}/pulls/{number}"

    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ PR
        pr_response = GLOBAL_SESSION.get(pr_url)
        if pr_response.status_code == 200:
            pr_data = pr_response.json()

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è PR
            state = pr_data['state']
            merged = pr_data.get('merged', False)
            draft = pr_data.get('draft', False)

            if state == 'closed' and merged:
                state_description = "–ó–∞–º–µ—Ä–¥–∂–µ–Ω üíú"
                embed_color = disnake.Color.purple()
            elif state == 'closed' and not merged:
                state_description = "–ó–∞–∫—Ä—ã—Ç ‚ùå"
                embed_color = disnake.Color.red()
            elif state == 'open' and draft:
                state_description = "–í –¥—Ä–∞—Ñ—Ç–µ ‚öôÔ∏è"
                embed_color = disnake.Color.darker_gray()
            elif state == 'open':
                state_description = "–û—Ç–∫—Ä—ã—Ç ‚úÖ"
                embed_color = disnake.Color.green()
            else:
                state_description = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å ‚ùì"
                embed_color = disnake.Color.default()

            # –°–æ–∑–¥–∞–µ–º embed
            embed = disnake.Embed(
                title=f"PR #{number} - {pr_data['title']}",
                color=embed_color
            )

            embed.add_field(name="–°—Ç–∞—Ç—É—Å PR", value=state_description, inline=True)

            # –°–æ–∑–¥–∞—Ç–µ–ª—å PR
            embed.add_field(name="–°–æ–∑–¥–∞—Ç–µ–ª—å PR üë®‚Äçüíª", value=pr_data['user']['login'], inline=True)

            # –†–µ–≤—å—é–µ—Ä—ã
            requested_reviewers = pr_data.get('requested_reviewers', [])
            reviewers_str = ', '.join([reviewer['login'] for reviewer in requested_reviewers]) if requested_reviewers else "–ù–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö üë•"

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –∫—Ç–æ –ø–æ—Å—Ç–∞–≤–∏–ª –æ—Ç–∑—ã–≤
            reviews_url = f"{pr_url}/reviews"
            reviews_response = GLOBAL_SESSION.get(reviews_url)
            if reviews_response.status_code == 200:
                reviews_data = reviews_response.json()
                reviewed_reviewers = [review['user']['login'] for review in reviews_data]

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö –∏ —Ç–µ—Ö, –∫—Ç–æ —É–∂–µ –ø–æ—Å—Ç–∞–≤–∏–ª –æ—Ç–∑—ã–≤ (–Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º)
                all_reviewers = set(requested_reviewers + reviewed_reviewers)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º set, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                all_reviewers_str = ', '.join(all_reviewers) if all_reviewers else "–ù–µ—Ç —Ä–µ–≤—å—é–µ—Ä–æ–≤"

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö —Ä–µ–≤—å—é–µ—Ä–∞—Ö
                embed.add_field(name="–†–µ–≤—å—é–µ—Ä—ã üîç", value=all_reviewers_str, inline=True)
            else:
                embed.add_field(name="–†–µ–≤—å—é–µ—Ä—ã üîç", value=reviewers_str, inline=True)

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–º, –∫—Ç–æ –æ–¥–æ–±—Ä–∏–ª (approved) PR
            reviews_url = f"{pr_url}/reviews"
            reviews_response = GLOBAL_SESSION.get(reviews_url)
            if reviews_response.status_code == 200:
                reviews_data = reviews_response.json()
                approved_reviewers = [review['user']['login'] for review in reviews_data if review['state'] == 'APPROVED']
                if approved_reviewers:
                    approved_reviewers_str = ', '.join(approved_reviewers)
                    embed.add_field(name="–û–¥–æ–±—Ä–µ–Ω–∏–µ üåü", value=approved_reviewers_str, inline=True)
                else:
                    embed.add_field(name="–û–¥–æ–±—Ä–µ–Ω–∏–µ üåü", value="–ù–µ—Ç –æ–¥–æ–±—Ä–µ–Ω–∏–π", inline=True)

            # –ú–µ—Ç–∫–∏ (Labels)
            labels = pr_data.get('labels', [])
            labels_str = ', '.join([label['name'] for label in labels]) if labels else "–ù–µ—Ç –º–µ—Ç–æ–∫ üè∑Ô∏è"
            embed.add_field(name="–ú–µ—Ç–∫–∏ üè∑Ô∏è", value=labels_str, inline=True)

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            comments_count = pr_data['comments']
            embed.add_field(name="–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ üí¨", value=comments_count, inline=True)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã –≤ –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥
            created_at = datetime.strptime(pr_data['created_at'], "%Y-%m-%dT%H:%M:%SZ")
            updated_at = datetime.strptime(pr_data['updated_at'], "%Y-%m-%dT%H:%M:%SZ")
            closed_at = pr_data.get('closed_at')  # –î–∞—Ç–∞ –∑–∞–∫—Ä—ã—Ç–∏—è (–µ—Å–ª–∏ PR –∑–∞–∫—Ä—ã—Ç)
            closed_at_str = ""
            if closed_at:
                closed_at = datetime.strptime(closed_at, "%Y-%m-%dT%H:%M:%SZ")
                closed_at_str = closed_at.strftime("‚Ä¢ –ó–∞–∫—Ä—ã—Ç {0}".format(closed_at.strftime("%d %b %Y, %H:%M")))

            created_at_str = created_at.strftime("%d %b %Y, %H:%M")  # –ù–∞–ø—Ä–∏–º–µ—Ä, 30 Jun 2024, 09:59
            updated_at_str = updated_at.strftime("%d %b %Y, %H:%M")  # –ù–∞–ø—Ä–∏–º–µ—Ä, 30 Jun 2024, 12:16

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PR —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            embed.set_footer(text=f"PR –æ—Ç–∫—Ä—ã—Ç {created_at_str} ‚Ä¢ –û–±–Ω–æ–≤–ª–µ–Ω {updated_at_str} {closed_at_str}")

            # –ó–∞–≤–µ—Ä—à–∞—é—â–∏–µ —Ç–µ–≥–∏
            if draft:
                embed.set_footer(text=f"–≠—Ç–æ—Ç PR –≤ —Ä–∞–±–æ—Ç–µ. #WIP ‚öôÔ∏è ‚Ä¢ {updated_at_str}")

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ —Ñ–∞–π–ª–∞—Ö –∏ —Å—Ç—Ä–æ–∫–∞—Ö
            file_changes = get_file_changes_from_github(pr_data['html_url'])
            if file_changes:
                # TODO: –î–æ–ø–∏—Å–∞—Ç—å, —á—Ç–æ–±—ã –≤—ã–≤–æ–¥–∏–ª–æ –∫–æ–ª-–≤–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                # embed.add_field(name="–ò–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã üìÇ", value=file_changes['new_files'], inline=True)
                embed.add_field(name="–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ üîÑ", value=f"–î–æ–±–∞–≤–ª–µ–Ω–æ: {file_changes['added_lines']}\n–£–¥–∞–ª–µ–Ω–æ: {file_changes['removed_lines']}", inline=True)

            # –°—Å—ã–ª–∫–∞ –Ω–∞ PR
            embed.add_field(name="–°—Å—ã–ª–∫–∞ –Ω–∞ PR üîó", value=f"[–ü–µ—Ä–µ–π—Ç–∏ –≤ PR]({pr_data['html_url']})", inline=False)

            return embed

        # –ï—Å–ª–∏ PR –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–∫–∞—Ç—å Issue
        issue_url = f"{base_api_url}/issues/{number}"
        issue_response = GLOBAL_SESSION.get(issue_url)
        if issue_response.status_code == 200:
            issue_data = issue_response.json()
            return f"[{repo_name} Issue {number}]({issue_data['html_url']})"

    except requests.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GitHub API: {e}")

    return None

def get_file_changes_from_github(pr_url):
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É PR –Ω–∞ GitHub, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤,
    –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫.
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        response = requests.get(pr_url)
        if response.status_code != 200:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {response.status_code}")
            return None

        # –ü–∞—Ä—Å–∏–º HTML —Å –ø–æ–º–æ—â—å—é BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        diffstat_element = soup.find('span', {'id': 'diffstat'})
        if diffstat_element:
            added_lines = diffstat_element.find('span', {'class': 'color-fg-success'}).text.strip() if diffstat_element.find('span', {'class': 'color-fg-success'}) else "–ù–µ –Ω–∞–π–¥–µ–Ω–æ"
            removed_lines = diffstat_element.find('span', {'class': 'color-fg-danger'}).text.strip() if diffstat_element.find('span', {'class': 'color-fg-danger'}) else "–ù–µ –Ω–∞–π–¥–µ–Ω–æ"
        else:
            added_lines = "–ù–µ –Ω–∞–π–¥–µ–Ω–æ"
            removed_lines = "–ù–µ –Ω–∞–π–¥–µ–Ω–æ"

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return {
            'added_lines': added_lines,
            'removed_lines': removed_lines
        }

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        return None